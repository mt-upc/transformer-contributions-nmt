{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "torch.cuda.set_device(2)\n",
    "torch.cuda.current_device()\n",
    "\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from wrappers.transformer_wrapper import FairseqTransformerHub\n",
    "from alignment.aer import aer\n",
    "import itertools\n",
    "\n",
    "import alignment.align as align\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "\n",
    "logger.setLevel('WARNING')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bilingual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "europarl_dir = Path(os.environ['EUROPARL_DATA_DIR'])\n",
    "ckpt_dir = Path(os.environ['EUROPARL_CKPT_DIR'])\n",
    "#iwslt14_dir = Path(os.environ['IWSLT14_DATA_DIR'])\n",
    "#ckpt_dir = Path(os.environ['IWSLT14_CKPT_DIR'])\n",
    "\n",
    "# Choose model\n",
    "model_type = 'baseline'\n",
    "seed = 5498 # 2253  2453  5498  9240\t9819\n",
    "model_name = f\"{model_type}/{seed}\"\n",
    "\n",
    "data_sample = 'interactive' # generate/interactive\n",
    "\n",
    "NUM_LAYERS = 6\n",
    "\n",
    "# Get sample from Gold alignment dataset\n",
    "# test_src_bpe = europarl_dir / \"processed_data/test.bpe.de\"\n",
    "# test_tgt_bpe = europarl_dir / \"processed_data/test.bpe.en\"\n",
    "\n",
    "# test_src_word = europarl_dir / \"data_in_progress/test.uc.de\"\n",
    "# test_tgt_word = europarl_dir / \"data_in_progress/test.uc.en\"\n",
    "\n",
    "gold_alignment = europarl_dir / \"gold_alignment/alignment.talp\"\n",
    "\n",
    "test_set_dir = europarl_dir / \"processed_data/\"\n",
    "src = \"de\"\n",
    "tgt = \"en\"\n",
    "tokenizer = \"bpe\"\n",
    "\n",
    "model_name_save = model_name.replace('/','_')\n",
    "store_filename = f'./results/alignments/{model_name_save}/extracted_matrix.pkl'\n",
    "\n",
    "pre_layer_norm = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub = FairseqTransformerHub.from_pretrained(\n",
    "    ckpt_dir / model_name,\n",
    "    checkpoint_file=f\"checkpoint_best.pt\",\n",
    "    data_name_or_path=(europarl_dir / \"processed_data/fairseq_preprocessed_data\").as_posix(), # processed data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilingual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = 'small' # small (412M) /big (1.2B)\n",
    "data_sample = 'interactive' # generate/interactive\n",
    "teacher_forcing = False # teacher forcing/free decoding\n",
    "\n",
    "# Paths\n",
    "# Checkpoint path\n",
    "ckpt_dir = Path(os.environ['M2M_CKPT_DIR'])\n",
    "\n",
    "NUM_LAYERS = 12\n",
    "\n",
    "model_name_save = f'm2m100_{model_size}'\n",
    "store_filename = f'./results/alignments/{model_name_save}/extracted_matrix.pkl'\n",
    "\n",
    "test_set_dir = Path(\"./data/de-en\")\n",
    "src = \"de\"\n",
    "tgt = \"en\"\n",
    "tokenizer = \"spm\"\n",
    "\n",
    "gold_alignment = test_set_dir / \"alignment.talp\"\n",
    "\n",
    "# Path to binarized data\n",
    "if data_sample == 'generate':\n",
    "    m2m_data_dir = Path(os.environ['M2M_DATA_DIR'])\n",
    "    data_name_or_path=(f'{m2m_data_dir}/data_bin')\n",
    "else:\n",
    "    # use \".\" to avoid loading\n",
    "    data_name_or_path='.'\n",
    "\n",
    "# Chackpoint names\n",
    "if model_size=='big':\n",
    "    checkpoint_file = '1.2B_last_checkpoint.pt'\n",
    "else:\n",
    "    checkpoint_file = '418M_last_checkpoint.pt'\n",
    "pre_layer_norm = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 20:41:06 | WARNING | fairseq.data.multilingual.multilingual_data_manager | External language dictionary is not provided; use lang-pairs to infer the set of supported languages. The language ordering is not stable which might cause misalignment in pretraining and finetuning.\n"
     ]
    }
   ],
   "source": [
    "from wrappers.multilingual_transformer_wrapper import FairseqMultilingualTransformerHub\n",
    "\n",
    "hub = FairseqMultilingualTransformerHub.from_pretrained(\n",
    "    ckpt_dir,\n",
    "    checkpoint_file=checkpoint_file,\n",
    "    data_name_or_path=data_name_or_path,\n",
    "    source_lang= 'de',\n",
    "    target_lang= 'en',\n",
    "    lang_pairs ='de-en')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute AER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_list = ['alti', 'decoder.encoder_attn', 'alti_enc_cross_attn']\n",
    "aer_obt = aer(test_set_dir, model_name_save, mode_list, NUM_LAYERS, src, tgt, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "contrib_type = 'l1'\n",
    "aer_obt.extract_contribution_matrix(hub, model_name_save, contrib_type,\n",
    "                                pre_layer_norm=pre_layer_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aer_obt.extract_alignments(final_punc_mark=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWI:\n",
      "\n",
      "Mode: alti\n",
      "[0.41421152501747727, 0.3838010586237891, 0.44407270548287225, 0.5724558074503145, 0.6523519424747828, 0.6881553979826226]\n",
      "\n",
      "Mode: decoder.encoder_attn\n",
      "[0.2561669829222012, 0.22106261859582543, 0.5246179966044142, 0.8418555877359433, 0.8218815539798262, 0.8439029261959452]\n",
      "\n",
      "Mode: alti_enc_cross_attn\n",
      "[0.41421152501747727, 0.37795865375012483, 0.587885748526915, 0.8095475881354239, 0.7896234894636972, 0.8222810346549485]\n",
      "\n",
      "AWO:\n",
      "\n",
      "Mode: alti\n",
      "[0.7648556876061121, 0.7424847697992609, 0.6704284430240688, 0.5896334764805753, 0.5265654648956357, 0.5130330570258663]\n",
      "\n",
      "Mode: decoder.encoder_attn\n",
      "[0.8267751922500749, 0.7947668031558973, 0.573204833716169, 0.484470188754619, 0.3423050034954559, 0.4892140217716968]\n",
      "\n",
      "Mode: alti_enc_cross_attn\n",
      "[0.7648556876061121, 0.7307500249675423, 0.5763008089483671, 0.5444422251073604, 0.4864675921302307, 0.5384500149805254]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_layers=NUM_LAYERS\n",
    "mode_list = ['alti', 'decoder.encoder_attn', 'alti_enc_cross_attn']\n",
    "\n",
    "for setting in ['AWI', 'AWO']:\n",
    "    print(f'{setting}:\\n')\n",
    "    results = aer_obt.calculate_aer(setting)\n",
    "    for mode in mode_list:\n",
    "        print('Mode:', mode)\n",
    "        print(results[mode]['aer'])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d90d8f5aa2056217711987bb6fa8dc20d62369a1e594ceedbb30cde0480a32e5"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
