{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "torch.cuda.set_device(2)\n",
    "torch.cuda.current_device()\n",
    "\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from wrappers.transformer_wrapper import FairseqTransformerHub\n",
    "from alignment.aer import aer\n",
    "import itertools\n",
    "\n",
    "import alignment.align as align\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "\n",
    "logger.setLevel('WARNING')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bilingual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "europarl_dir = Path(os.environ['EUROPARL_DATA_DIR'])\n",
    "ckpt_dir = Path(os.environ['EUROPARL_CKPT_DIR'])\n",
    "#iwslt14_dir = Path(os.environ['IWSLT14_DATA_DIR'])\n",
    "#ckpt_dir = Path(os.environ['IWSLT14_CKPT_DIR'])\n",
    "\n",
    "# Choose model\n",
    "model_type = 'baseline'\n",
    "seed = 9819 # 2253  2453  5498  924  9819\n",
    "model_name = f\"{model_type}/{seed}\"\n",
    "\n",
    "data_sample = 'interactive' # generate/interactive\n",
    "\n",
    "NUM_LAYERS = 6\n",
    "\n",
    "# Get sample from Gold alignment dataset\n",
    "# test_src_bpe = europarl_dir / \"processed_data/test.bpe.de\"\n",
    "# test_tgt_bpe = europarl_dir / \"processed_data/test.bpe.en\"\n",
    "\n",
    "# test_src_word = europarl_dir / \"data_in_progress/test.uc.de\"\n",
    "# test_tgt_word = europarl_dir / \"data_in_progress/test.uc.en\"\n",
    "\n",
    "gold_alignment = europarl_dir / \"gold_alignment/alignment.talp\"\n",
    "\n",
    "test_set_dir = europarl_dir / \"processed_data/\"\n",
    "src = \"de\"\n",
    "tgt = \"en\"\n",
    "tokenizer = \"bpe\"\n",
    "\n",
    "model_name_save = model_name.replace('/','_')\n",
    "store_filename = f'./results/alignments/{model_name_save}/extracted_matrix.pkl'\n",
    "\n",
    "pre_layer_norm = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub = FairseqTransformerHub.from_pretrained(\n",
    "    ckpt_dir / model_name,\n",
    "    checkpoint_file=f\"checkpoint_best.pt\",\n",
    "    data_name_or_path=(europarl_dir / \"processed_data/fairseq_preprocessed_data\").as_posix(), # processed data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilingual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = 'small' # small (412M) /big (1.2B)\n",
    "data_sample = 'interactive' # generate/interactive\n",
    "teacher_forcing = False # teacher forcing/free decoding\n",
    "\n",
    "# Paths\n",
    "# Checkpoint path\n",
    "ckpt_dir = Path(os.environ['M2M_CKPT_DIR'])\n",
    "\n",
    "NUM_LAYERS = 12\n",
    "\n",
    "model_name_save = f'm2m100_{model_size}'\n",
    "store_filename = f'./results/alignments/{model_name_save}/extracted_matrix.pkl'\n",
    "\n",
    "test_set_dir = Path(\"./data/de-en\")\n",
    "src = \"de\"\n",
    "tgt = \"en\"\n",
    "tokenizer = \"spm\"\n",
    "\n",
    "gold_alignment = test_set_dir / \"alignment.talp\"\n",
    "\n",
    "# Path to binarized data\n",
    "if data_sample == 'generate':\n",
    "    m2m_data_dir = Path(os.environ['M2M_DATA_DIR'])\n",
    "    data_name_or_path=(f'{m2m_data_dir}/data_bin')\n",
    "else:\n",
    "    # use \".\" to avoid loading\n",
    "    data_name_or_path='.'\n",
    "\n",
    "# Chackpoint names\n",
    "if model_size=='big':\n",
    "    checkpoint_file = '1.2B_last_checkpoint.pt'\n",
    "else:\n",
    "    checkpoint_file = '418M_last_checkpoint.pt'\n",
    "pre_layer_norm = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 20:41:06 | WARNING | fairseq.data.multilingual.multilingual_data_manager | External language dictionary is not provided; use lang-pairs to infer the set of supported languages. The language ordering is not stable which might cause misalignment in pretraining and finetuning.\n"
     ]
    }
   ],
   "source": [
    "from wrappers.multilingual_transformer_wrapper import FairseqMultilingualTransformerHub\n",
    "\n",
    "hub = FairseqMultilingualTransformerHub.from_pretrained(\n",
    "    ckpt_dir,\n",
    "    checkpoint_file=checkpoint_file,\n",
    "    data_name_or_path=data_name_or_path,\n",
    "    source_lang= 'de',\n",
    "    target_lang= 'en',\n",
    "    lang_pairs ='de-en')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute AER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_list = ['alti', 'decoder.encoder_attn', 'alti_enc_cross_attn','attn_w']\n",
    "aer_obt = aer(test_set_dir, model_name_save, mode_list, NUM_LAYERS, src, tgt, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "contrib_type = 'l1'\n",
    "aer_obt.extract_contribution_matrix(hub, model_name_save, contrib_type,\n",
    "                                pre_layer_norm=pre_layer_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alti\n",
      "decoder.encoder_attn\n",
      "alti_enc_cross_attn\n",
      "attn_w\n",
      "alti\n",
      "decoder.encoder_attn\n",
      "alti_enc_cross_attn\n",
      "attn_w\n"
     ]
    }
   ],
   "source": [
    "aer_obt.extract_alignments(final_punc_mark=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWI:\n",
      "\n",
      "Mode: alti\n",
      "[0.5973234794766803, 0.4379306901028662, 0.4624488165384999, 0.5834415260161789, 0.6851093578348147, 0.700838909417757]\n",
      "\n",
      "Mode: decoder.encoder_attn\n",
      "[0.47103765105363027, 0.2602533927587761, 0.3611249875112399, 0.8550934048921457, 0.830720063916908, 0.8438843884388438]\n",
      "\n",
      "Mode: alti_enc_cross_attn\n",
      "[0.5973234794766803, 0.41980425446919, 0.4998002596624388, 0.8016479400749064, 0.8072505742534705, 0.8353140916808149]\n",
      "\n",
      "Mode: attn_w\n",
      "[0.6170462894930198, 0.2819765747916788, 0.46417410080118193, 0.9033638068448195, 0.9321608040201005, 0.9402746494223643]\n",
      "\n",
      "AWO:\n",
      "\n",
      "Mode: alti\n",
      "[0.7944172575651653, 0.7859782283032059, 0.7295016478577849, 0.6367721961450115, 0.5687106761210426, 0.5575751523020074]\n",
      "\n",
      "Mode: decoder.encoder_attn\n",
      "[0.8521921502047338, 0.8555378008588834, 0.6951499999999999, 0.47756297006713444, 0.38919404773794064, 0.5158]\n",
      "\n",
      "Mode: alti_enc_cross_attn\n",
      "[0.7944172575651653, 0.7869269949066213, 0.6630380505343054, 0.5599720363527414, 0.5099870168780585, 0.5739039248976331]\n",
      "\n",
      "Mode: attn_w\n",
      "[0.9181712288875946, 0.8862258322846356, 0.6764975900849208, 0.49905611807104855, 0.5047549821309589, 0.6424573088641679]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_layers=NUM_LAYERS\n",
    "mode_list = ['alti', 'decoder.encoder_attn', 'alti_enc_cross_attn', 'attn_w']\n",
    "\n",
    "for setting in ['AWI', 'AWO']:\n",
    "    print(f'{setting}:\\n')\n",
    "    results = aer_obt.calculate_aer(setting)\n",
    "    for mode in mode_list:\n",
    "        print('Mode:', mode)\n",
    "        print(results[mode]['aer'])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d90d8f5aa2056217711987bb6fa8dc20d62369a1e594ceedbb30cde0480a32e5"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
