{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from fairseq.models.transformer_lm import TransformerLanguageModel\n",
    "import torch\n",
    "torch.cuda.set_device(2)\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/home/usuaris/scratch/belen.alastruey\"\n",
    "# custom_lm = TransformerLanguageModel.from_pretrained(path, 'checkpoint_best.pt', bpe='sentencepiece', sentencepiece_model=path + \"/en.model\")\n",
    "# custom_lm.score('ladies and gentlemen , i would like to begin by thanking the rapporteur , mr gra√ßa moura , for his report .', beam=5)\n",
    "# custom_lm.sample('ladies and gentlemen', beam=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq_transformer_wrapper import FairseqTransformerHub, parse_single_alignment\n",
    "import warnings\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-09 18:31:01 | INFO | fairseq.file_utils | loading archive file /home/usuaris/scratch/belen.alastruey/europarl_lm_ckpt\n",
      "2022-02-09 18:31:01 | INFO | fairseq.file_utils | loading archive file /home/usuaris/scratch/belen.alastruey/data-bin\n",
      "2022-02-09 18:31:01 | INFO | fairseq.tasks.language_modeling | dictionary: 10001 types\n",
      "2022-02-09 18:31:02 | INFO | fairseq.models.fairseq_model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': 'lm', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/home/usuaris/scratch/belen.alastruey/europarl_lm_ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 1024, 'decoder_layers': 6, 'decoder_attention_heads': 4, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': '/home/usuaris/scratch/belen.alastruey/data-bin', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n"
     ]
    }
   ],
   "source": [
    "europarl_dir = \"/home/usuaris/veu/javier.ferrando/norm-analysis-of-transformer/exp2_nmt/work/\"\n",
    "ckpt_dir = \"/home/usuaris/scratch/belen.alastruey/europarl_lm_ckpt\"\n",
    "#ckpt_dir = \"/home/usuaris/scratch/belen.alastruey\"\n",
    "#dict_dir = \"/home/usuaris/veu/belen.alastruey/europarl_lm_data/data-bin\"\n",
    "dict_dir = \"/home/usuaris/scratch/belen.alastruey/data-bin\"\n",
    "\n",
    "### Alignment test (BPE from Europarl)\n",
    "test_de_bpe = europarl_dir + \"processed_data/test.bpe.de\"\n",
    "test_de_word =  europarl_dir + \"processed_data/test.de\"\n",
    "test_en_bpe = europarl_dir + \"processed_data/test.bpe.en\"\n",
    "test_en_word = europarl_dir + \"processed_data/test.en\"\n",
    "gold_alignment = europarl_dir + \"gold_alignment/alignment.talp\"\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "with open(test_de_bpe, encoding=\"utf-8\") as fbpe:\n",
    "    src_bpe_sents = fbpe.readlines()\n",
    "with open(test_en_bpe, encoding=\"utf-8\") as fbpe:\n",
    "    tgt_bpe_sents = fbpe.readlines()\n",
    "with open(europarl_dir + \"data_in_progress/test.uc.de\", encoding=\"utf-8\") as fword:\n",
    "    src_word_sents = fword.readlines()\n",
    "with open(europarl_dir + \"data_in_progress/test.uc.en\", encoding=\"utf-8\") as fword:\n",
    "    tgt_word_sents = fword.readlines()\n",
    "\n",
    "\n",
    "hub = FairseqTransformerHub.from_pretrained(\n",
    "    ckpt_dir,\n",
    "    checkpoint_file=f\"checkpoint_best.pt\",\n",
    "    data_name_or_path=(dict_dir),\n",
    "    #(data_name_or_path=iwslt14_dir / \"data-bin\").as_posix(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-09 18:31:04 | INFO | fairseq.data.data_utils | loaded 508 examples from: /home/usuaris/scratch/belen.alastruey/data-bin/test\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "i = 0 # 0, 1 28, 45, 148 (pred_tok vs tgt_tok), 178, 16 (Hallucination)\n",
    "\n",
    "src_sent, src_tok, src_tensor = hub.get_lm_sample('test', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'we do not believe that we should cherry-pick .but this is not what happens .of course , if a drug addict becomes a pusher , then it is right and necessary that he should pay and answer before the law also .commissioner , ladies and gentlemen , i should like to begin by thanking mr burtone for his report .<unk> legal drugs <unk> ( tranquillizers ) finding their way on to an illegal market , especially when used in combination with alcohol , are a major and serious problem particularly for young people .i should like to take this opportunity to express my thanks to mr titley .it was a very difficult position and i therefore am delighted about the new agreement .we must accept that , in the realm of blood and plasma collection , the systems vary and operate on mixed bases .the minutes of yesterday <unk>s sitting have been distributed .to this end the oostlander report takes substantial note of the european commission guidelines which are very clear , very precise and do not leave room for subjective interpretation .europe should not get over ambitious by trying to manage public health policy .in any event , the national front demands that the peoples of europe should be directly consulted in a referendum to decide on the approval or rejection of maastricht ii .the authors of the report consider that enlargement to the east is undoubtedly possible in theory , but will be far more difficult in practice .i would ask you , members of the european parliament present here , to support this amendment by mrs stenius-kaukonen which all members of the finnish parliament across party boundaries support .they are silting up .france was the first to take diplomatic and humanitarian action .i constantly bring this matter up both in writing to the president and to the heads of the political groups .question no 7 by mar√≠a izquierdo rojo ( h-0252 / 96 )it is a question of how decisions are taken , that is to say whether this is done on the basis of a vote or of consensus , and whether unanimity is required or some form of qualified majority .nepal is very high up and helping this country where needs are very great must also be high up on our list .this commitment to negotiations between the social partners could initially be reached on four matters , which seem to me essential , as of now . negotiations must begin .the committee on transport and tourism'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_tensor = src_tensor.unsqueeze(0).to(device)\n",
    "# tgt_tensor = torch.cat([\n",
    "#     torch.tensor([self.task.tgt_dict.eos_index]),\n",
    "#     tgt_tensor[:-1]\n",
    "#     ]).unsqueeze(0).to(self.device)\n",
    "\n",
    "# model_output, encoder_out = self.models[0](src_tensor, src_tensor.size(-1), tgt_tensor, )\n",
    "\n",
    "# log_probs = self.models[0].get_normalized_probs(model_output, log_probs=True, sample=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output, log_probs, encoder_out, layer_inputs, layer_outputs = hub.trace_lm_forward(src_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs torch.Size([512, 10001])\n",
      "torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "probs = torch.nn.functional.softmax(log_probs, dim=-1)\n",
    "print('probs',probs.size())\n",
    "pred_ind = torch.argmax(probs,dim=-1)\n",
    "print(pred_ind.size())\n",
    "pred = torch.max(probs,dim=-1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.1324, 0.1331, 0.9158, 0.2433, 0.7275, 0.2566, 0.3067, 0.1303, 0.6539,\n",
       "        0.8635, 0.2156, 0.1991, 0.6005, 0.7885, 0.9541, 0.3908, 0.3348, 0.4230,\n",
       "        0.2484, 0.2070, 0.5856, 0.3318, 0.9750, 0.2948, 0.9861, 0.4293, 0.3794,\n",
       "        0.5040, 0.1245, 0.3957, 0.9941, 0.3281, 0.4382, 0.2849, 0.6068, 0.5862,\n",
       "        0.2288, 0.2559, 0.4527, 0.1248, 0.4309, 0.8498, 0.3810, 0.4883, 0.6681,\n",
       "        0.3132, 0.0995, 0.1433, 0.2859, 0.2204, 0.2984, 0.4929, 0.1873, 0.9922,\n",
       "        0.1302, 0.9389, 0.2174, 0.9997, 0.9999, 0.9888, 0.3022, 0.1779, 0.7726,\n",
       "        0.9213, 0.1495, 0.9308, 0.3320, 0.4062, 0.0810, 0.8342, 0.9776, 0.8506,\n",
       "        0.6273, 0.3768, 0.3687, 0.9780, 0.2071, 0.0459, 0.1334, 0.4097, 0.6145,\n",
       "        0.3618, 0.1248, 0.1340, 0.5406, 0.8734, 0.8165, 0.1584, 0.6659, 0.4643,\n",
       "        0.3473, 0.6764, 0.5239, 0.5841, 0.4260, 0.1474, 0.1369, 0.4098, 0.1238,\n",
       "        0.2507, 0.2827, 0.2580, 0.2420, 0.9594, 0.2201, 0.3300, 0.1661, 0.0801,\n",
       "        0.0503, 0.2759, 0.1180, 0.6290, 0.4920, 0.5263, 0.2545, 0.9123, 0.5697,\n",
       "        0.9863, 0.1337, 0.2783, 0.6014, 0.9203, 0.0848, 0.8416, 0.9953, 0.8834,\n",
       "        0.2185, 0.8726, 0.1431, 0.4548, 0.4365, 0.9232, 0.9322, 0.7176, 0.9782,\n",
       "        0.1416, 0.6887, 0.2124, 0.2219, 0.2356, 0.3025, 0.4330, 0.4171, 0.2212,\n",
       "        0.1110, 0.1850, 0.5015, 0.3857, 0.1247, 0.0886, 0.2533, 0.9835, 0.2348,\n",
       "        0.2416, 0.1338, 0.5635, 0.2207, 0.1099, 0.1917, 0.0855, 0.5204, 0.9673,\n",
       "        0.1120, 0.2646, 0.1799, 0.3958, 0.9930, 0.5013, 0.7535, 0.1803, 0.0505,\n",
       "        0.2614, 0.2057, 0.1100, 0.0984, 0.3909, 0.0994, 0.5405, 0.9683, 0.1112,\n",
       "        0.0450, 0.6349, 0.6443, 0.9910, 0.1633, 0.1459, 0.1270, 0.4201, 0.8884,\n",
       "        0.8683, 0.9532, 0.9938, 0.9935, 0.2108, 0.3357, 0.8752, 0.1344, 0.2642,\n",
       "        0.9922, 0.9731, 0.2151, 0.2409, 0.3592, 0.9295, 0.5846, 0.3233, 0.8660,\n",
       "        0.8059, 0.2900, 0.1535, 0.1040, 0.1350, 0.2553, 0.1375, 0.4644, 0.6748,\n",
       "        0.1675, 0.7960, 0.0898, 0.3003, 0.9857, 0.1775, 0.8844, 0.1339, 0.6439,\n",
       "        0.9799, 0.1638, 0.2034, 0.1873, 0.2235, 0.1621, 0.2954, 0.2114, 0.0361,\n",
       "        0.9203, 0.0420, 0.3012, 0.6930, 0.2031, 0.1177, 0.9626, 0.1459, 0.1592,\n",
       "        0.5997, 0.9125, 0.2045, 0.1097, 0.1875, 0.3070, 0.2406, 0.2710, 0.2258,\n",
       "        0.6524, 0.8407, 0.2135, 0.2573, 0.1738, 0.8050, 0.1791, 0.2558, 0.1278,\n",
       "        0.3739, 0.1877, 0.2420, 0.3181, 0.1182, 0.9088, 0.1108, 0.9735, 0.2944,\n",
       "        0.3674, 0.4575, 0.9827, 0.1142, 0.0931, 0.6299, 0.4632, 0.5516, 0.2128,\n",
       "        0.5550, 0.3337, 0.2356, 0.5567, 0.8678, 0.3009, 0.3183, 0.4524, 0.2694,\n",
       "        0.2656, 0.3084, 0.5860, 0.2319, 0.2561, 0.0976, 0.3532, 0.2444, 0.2635,\n",
       "        0.2620, 0.3045, 0.9848, 0.1500, 0.2795, 0.3000, 0.4159, 0.5924, 0.3014,\n",
       "        0.9514, 0.4048, 0.6809, 0.9355, 0.9457, 0.4758, 0.4333, 0.7095, 0.0801,\n",
       "        0.3404, 0.6901, 0.3781, 0.4996, 0.0740, 0.8206, 0.9863, 0.7065, 0.4728,\n",
       "        0.3439, 0.1098, 0.3502, 0.2258, 0.3067, 0.4115, 0.1275, 0.2745, 0.6819,\n",
       "        0.6071, 0.6522, 0.7174, 0.1521, 0.7886, 0.4801, 0.1959, 0.5482, 0.9821,\n",
       "        0.3031, 0.1599, 0.1064, 0.7489, 0.2229, 0.3228, 0.9428, 0.1392, 0.1474,\n",
       "        0.2270, 0.1189, 0.4646, 0.6544, 0.0686, 0.2261, 0.7647, 0.2651, 0.7243,\n",
       "        0.1804, 0.9603, 0.1087, 0.1715, 0.1071, 0.1636, 0.1786, 0.5103, 0.1411,\n",
       "        0.1780, 0.3282, 0.9726, 0.5861, 0.0910, 0.4767, 0.2355, 0.8836, 0.2248,\n",
       "        0.9943, 0.6298, 0.1863, 0.4280, 0.4095, 0.9708, 0.1925, 0.8564, 0.0707,\n",
       "        0.9703, 0.2831, 0.5503, 0.7036, 0.9969, 0.9985, 0.9990, 0.9994, 0.7630,\n",
       "        0.9978, 0.9938, 0.9984, 0.9998, 0.2789, 0.1974, 0.4866, 0.9524, 0.3349,\n",
       "        0.9989, 0.9731, 0.9992, 0.6373, 0.1018, 0.2041, 0.9050, 0.0909, 0.2065,\n",
       "        0.2466, 0.4876, 0.2275, 0.2600, 0.6810, 0.4865, 0.8003, 0.2404, 0.3056,\n",
       "        0.3402, 0.3292, 0.1729, 0.3443, 0.8510, 0.9941, 0.1710, 0.0396, 0.1515,\n",
       "        0.2339, 0.5729, 0.3809, 0.1800, 0.4298, 0.1761, 0.3691, 0.2270, 0.3237,\n",
       "        0.5408, 0.0769, 0.9870, 0.5353, 0.9829, 0.3088, 0.9814, 0.1579, 0.1917,\n",
       "        0.1891, 0.1303, 0.2000, 0.2389, 0.6097, 0.2262, 0.1313, 0.3161, 0.1671,\n",
       "        0.4669, 0.1575, 0.3783, 0.0549, 0.1226, 0.6434, 0.3167, 0.8263, 0.1133,\n",
       "        0.9468, 0.4362, 0.7123, 0.5945, 0.4409, 0.9753, 0.1687, 0.4048, 0.1890,\n",
       "        0.2550, 0.1980, 0.6697, 0.2659, 0.8503, 0.2261, 0.3480, 0.5583, 0.0570,\n",
       "        0.1070, 0.3126, 0.1813, 0.3411, 0.1652, 0.2311, 0.5967, 0.5655, 0.7236,\n",
       "        0.3154, 0.2761, 0.1365, 0.4305, 0.3538, 0.9533, 0.2147, 0.3889, 0.1201,\n",
       "        0.9757, 0.1638, 0.1076, 0.7234, 0.1634, 0.8240, 0.9987, 0.2180],\n",
       "       device='cuda:2', grad_fn=<MaxBackward0>),\n",
       "indices=tensor([ 119,  110,  109,  569,   55,    8,  199,   50,   18,  244,  145,   37,\n",
       "        8186,   47,    2,  171,   73,   54,  109,    8,   73,   31,    2,  171,\n",
       "         814,   17,   73,   73,  280,   54,  974,   54,    6, 2439,  145,   17,\n",
       "         878,   82,   54,  109,   55, 1420,   28,   73,  211,   50,   66,   55,\n",
       "           8,  240,  724,   24,   24,    2,  171,   17,   61,   37,  908,   17,\n",
       "          61,  196,  296,   28,  987,  149, 4531,    8, 6901, 9792,  345,   66,\n",
       "         844,  257,   24,    2, 9794,  179, 1210,   96, 3747,  641,   37,  983,\n",
       "         151,  108, 9793,  321,  321,   96, 1694,  520,  485,    8,    8, 1064,\n",
       "        2439,   54,   37,   31,   82,   31,    8,  105,    8,   17,   54,  109,\n",
       "         877,  877, 1037,  877,   24,   31, 1777,  385,   24,    2,  119,  211,\n",
       "         197,   28,  987,   89, 1228,   28,  987,  373,  376,   28,    8, 1812,\n",
       "        5026,   66,    2, 9794,   54,    6,  316,  628,  257,   28,   61,  211,\n",
       "         574,  316,   55,    8,  512, 1082,   24,    2, 9794,  110,  109,   55,\n",
       "           8,   31,    8,  677,  678,   27, 3272,   17, 4608,   58, 3308,   17,\n",
       "          17,   73,  690,   27,  223,    8,   31,    6, 3378,   24,    2,  171,\n",
       "         877,   27, 2806,  150, 9865, 9883,  141,  110,  239, 5826,   24,    2,\n",
       "         383, 5172,  724,   17, 1527, 2215, 9332,  257,  164,    6, 2695,   27,\n",
       "           8,  512,  238,  150,   64,  110,  451,  541,   24,   37,  541,   37,\n",
       "         316,  109, 1736,    8,   66, 2146,  133, 1940,   24,    2, 9794,  150,\n",
       "         109,   50, 1435,    8, 1472,    8,   28,  482,    8,  880,  919,   24,\n",
       "           2,  171,   89,  827,   17,   61,  257, 1776,  211,   55,    8,  280,\n",
       "          27,  103,   50,   50,  842, 1435,   64,    8,  609,   24, 2689, 1001,\n",
       "           8,  677,   27, 3527,   27,    8,   24,   24,    2,  119,  128,   27,\n",
       "           8,  257,   96,   55,    8,  211, 1853, 1468,   54,    6,    6,   17,\n",
       "           8,   24,  235,   82,  109,    6,  277,  997,  359, 1954,   24,    2,\n",
       "         119,  211,  296,  260,   28,  602,   27,    8,  128,  238,   17,   17,\n",
       "          17,   28,  957,    8,  257,   24,    8, 1119, 9673, 9825,  194, 9825,\n",
       "          37,   17,   24,   17, 2264,   24,   17,    8,   27,    8,  128,  238,\n",
       "         110,    8, 8253,  110,   24,    2,  393,   96,  109, 3569,    8,    8,\n",
       "           2, 9794, 8338,   54,    8,  549,  647, 6015,  201,  840,  545,  840,\n",
       "          31,    2,  119,  203, 2129,    8,   28,   28,   37,   31,    8,   37,\n",
       "           8,  625,   27,    8,    8,  214,   27,  550,  128, 1551,   24,    2,\n",
       "        9794,  308,  283,  149,  453, 8860,   80, 9825,  151, 2147, 2694,  491,\n",
       "        8549,  453,   45,  145, 4123, 9824,  733,  733, 4185,  321,    2, 4371,\n",
       "          54,    6,  629,   27,    8,    8,   96,  820,   24,   37,   54,   17,\n",
       "         477,   17,    8,   54,    6,   31,    6, 1042,   27,    8,  743,   24,\n",
       "        1001,    6,   24,  182, 1001,   82,   54, 2091,   24, 1001,  280,   27,\n",
       "        5626, 1508,   24,    2, 9794, 1166, 9798,   21,    6,  394,   64,   64,\n",
       "        1196,   28,  752,   28,    8,   96,  716,  997,   24, 9797,   50,  967,\n",
       "         356,   24,    8, 1626,   27,    2, 9794,   54,  227,    8,  105,    8,\n",
       "         128, 1320,   54,   50,   50,    6,   17,    8, 1378,   24, 2074,   96,\n",
       "          28,  115,   28,   28,  235,    8,  814,   17,    2,  495,   50,   64,\n",
       "           2,  119,  549,   64, 2723,   37, 2719,  164], device='cuda:2'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "29dddf07111d89c3e552500cd49efba8f38c918b978a2b24ef1c9934f64adf3f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('local_att': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
