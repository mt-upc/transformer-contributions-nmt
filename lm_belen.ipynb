{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 18:36:07 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lm_fairseq_transformer_wrapper import FairseqTransformerHub, parse_single_alignment\n",
    "import warnings\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "torch.cuda.set_device(1)\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 21:07:33 | INFO | fairseq.file_utils | Archive name '/home/usuaris/veu/belen.alastruey/europarl_lm_ckpt/' was not found in archive name list. We assumed '/home/usuaris/veu/belen.alastruey/europarl_lm_ckpt/' was a path or URL but couldn't find any file associated to this path or URL.\n",
      "2022-03-12 21:07:33 | INFO | fairseq.file_utils | Archive name '/home/usuaris/veu/belen.alastruey/europarl_lm_data/data-bin' was not found in archive name list. We assumed '/home/usuaris/veu/belen.alastruey/europarl_lm_data/data-bin' was a path or URL but couldn't find any file associated to this path or URL.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d1b9b7406867>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mckpt_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"checkpoint_best.pt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mdata_name_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;31m#(data_name_or_path=iwslt14_dir / \"data-bin\").as_posix(),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m )\n",
      "\u001b[0;32m~/transformer-contributions-nmt/lm_fairseq_transformer_wrapper.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, checkpoint_dir, checkpoint_file, data_name_or_path)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_name_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mhub_interface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_name_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhub_interface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhub_interface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhub_interface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fairseq/fairseq/models/fairseq_model.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, model_name_or_path, checkpoint_file, data_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mdata_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0marchive_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         )\n\u001b[1;32m    271\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fairseq/fairseq/hub_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(model_name_or_path, checkpoint_file, data_name_or_path, archive_map, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;34m\"vocab.json\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"bpe_vocab\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     }.items():\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/int_nmt/lib/python3.6/posixpath.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mdiscarded\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mAn\u001b[0m \u001b[0mempty\u001b[0m \u001b[0mlast\u001b[0m \u001b[0mpart\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mthat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     ends with a separator.\"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_sep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "europarl_dir = \"/home/usuaris/veu/javier.ferrando/norm-analysis-of-transformer/exp2_nmt/work/\"\n",
    "ckpt_dir = \"/home/usuaris/veu/belen.alastruey/europarl_lm_ckpt/\"\n",
    "dict_dir = \"/home/usuaris/veu/belen.alastruey/europarl_lm_data/data-bin\"\n",
    "\n",
    "### Alignment test (BPE from Europarl)\n",
    "test_de_bpe = europarl_dir + \"processed_data/test.bpe.de\"\n",
    "test_de_word =  europarl_dir + \"processed_data/test.de\"\n",
    "test_en_bpe = europarl_dir + \"processed_data/test.bpe.en\"\n",
    "test_en_word = europarl_dir + \"processed_data/test.en\"\n",
    "gold_alignment = europarl_dir + \"gold_alignment/alignment.talp\"\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "with open(test_de_bpe, encoding=\"utf-8\") as fbpe:\n",
    "    src_bpe_sents = fbpe.readlines()\n",
    "with open(test_en_bpe, encoding=\"utf-8\") as fbpe:\n",
    "    tgt_bpe_sents = fbpe.readlines()\n",
    "with open(europarl_dir + \"data_in_progress/test.uc.de\", encoding=\"utf-8\") as fword:\n",
    "    src_word_sents = fword.readlines()\n",
    "with open(europarl_dir + \"data_in_progress/test.uc.en\", encoding=\"utf-8\") as fword:\n",
    "    tgt_word_sents = fword.readlines()\n",
    "\n",
    "\n",
    "hub = FairseqTransformerHub.from_pretrained(\n",
    "    ckpt_dir,\n",
    "    checkpoint_file=f\"checkpoint_best.pt\",\n",
    "    data_name_or_path=(dict_dir),\n",
    "    #(data_name_or_path=iwslt14_dir / \"data-bin\").as_posix(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LanguageModelingTask' object has no attribute 'src_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/usuaris/veu/belen.alastruey/transformer-contributions-nmt/lm.ipynb Cell 8'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcalcula/home/usuaris/veu/belen.alastruey/transformer-contributions-nmt/lm.ipynb#ch0000008vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m# Test data\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcalcula/home/usuaris/veu/belen.alastruey/transformer-contributions-nmt/lm.ipynb#ch0000008vscode-remote?line=1'>2</a>\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m# 0, 1 28, 45, 148 (pred_tok vs tgt_tok), 178, 16 (Hallucination)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcalcula/home/usuaris/veu/belen.alastruey/transformer-contributions-nmt/lm.ipynb#ch0000008vscode-remote?line=3'>4</a>\u001b[0m src_sent, src_tok, src_tensor, tgt_sent, tgt_tok, tgt_tensor \u001b[39m=\u001b[39m hub\u001b[39m.\u001b[39;49mget_sample(\u001b[39m'\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m'\u001b[39;49m, i)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcalcula/home/usuaris/veu/belen.alastruey/transformer-contributions-nmt/lm.ipynb#ch0000008vscode-remote?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mSource sentence: \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00msrc_sent\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcalcula/home/usuaris/veu/belen.alastruey/transformer-contributions-nmt/lm.ipynb#ch0000008vscode-remote?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTarget sentence: \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mtgt_sent\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/transformer-contributions-nmt/fairseq_transformer_wrapper.py:61\u001b[0m, in \u001b[0;36mFairseqTransformerHub.get_sample\u001b[0;34m(self, split, index)\u001b[0m\n\u001b[1;32m     <a href='file:///~/transformer-contributions-nmt/fairseq_transformer_wrapper.py?line=57'>58</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask\u001b[39m.\u001b[39mload_dataset(split)\n\u001b[1;32m     <a href='file:///~/transformer-contributions-nmt/fairseq_transformer_wrapper.py?line=59'>60</a>\u001b[0m src_tensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask\u001b[39m.\u001b[39mdataset(split)[index][\u001b[39m'\u001b[39m\u001b[39msource\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> <a href='file:///~/transformer-contributions-nmt/fairseq_transformer_wrapper.py?line=60'>61</a>\u001b[0m src_tok \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecode(src_tensor, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtask\u001b[39m.\u001b[39;49msrc_dict)\n\u001b[1;32m     <a href='file:///~/transformer-contributions-nmt/fairseq_transformer_wrapper.py?line=61'>62</a>\u001b[0m src_sent \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecode(src_tensor, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask\u001b[39m.\u001b[39msrc_dict, as_string\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='file:///~/transformer-contributions-nmt/fairseq_transformer_wrapper.py?line=63'>64</a>\u001b[0m tgt_tensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask\u001b[39m.\u001b[39mdataset(split)[index][\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LanguageModelingTask' object has no attribute 'src_dict'"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "i = 1 # 0, 1 28, 45, 148 (pred_tok vs tgt_tok), 178, 16 (Hallucination)\n",
    "\n",
    "src_sent, src_tok, src_tensor, tgt_sent, tgt_tok, tgt_tensor = hub.get_sample('test', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_tensor = src_tensor.unsqueeze(0).to(device)\n",
    "# tgt_tensor = torch.cat([\n",
    "#     torch.tensor([self.task.tgt_dict.eos_index]),\n",
    "#     tgt_tensor[:-1]\n",
    "#     ]).unsqueeze(0).to(self.device)\n",
    "\n",
    "# model_output, encoder_out = self.models[0](src_tensor, src_tensor.size(-1), tgt_tensor, )\n",
    "\n",
    "# log_probs = self.models[0].get_normalized_probs(model_output, log_probs=True, sample=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'src_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/usuaris/veu/belen.alastruey/transformer-contributions-nmt/lm.ipynb Cell 10'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcalcula/home/usuaris/veu/belen.alastruey/transformer-contributions-nmt/lm.ipynb#ch0000011vscode-remote?line=0'>1</a>\u001b[0m model_output, log_probs, encoder_out, layer_inputs, layer_outputs \u001b[39m=\u001b[39m hub\u001b[39m.\u001b[39mtrace_forward(src_tensor, tgt_tensor)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'src_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "model_output, log_probs, encoder_out, layer_inputs, layer_outputs = hub.trace_forward(src_tensor, tgt_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.nn.functional.softmax(log_probs, dim=-1)\n",
    "print('probs',probs.size())\n",
    "pred_ind = torch.argmax(probs,dim=-1)\n",
    "print(pred_ind.size())\n",
    "pred = torch.max(probs,dim=-1)\n",
    "pred\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "29dddf07111d89c3e552500cd49efba8f38c918b978a2b24ef1c9934f64adf3f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('local_att': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
