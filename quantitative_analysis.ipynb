{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "torch.cuda.set_device(4)\n",
    "torch.cuda.current_device()\n",
    "\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from wrappers.transformer_wrapper import FairseqTransformerHub\n",
    "\n",
    "import alignment.align as align\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "import statistics\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "\n",
    "logger.setLevel('WARNING')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = 'interactive' # generate/interactive\n",
    "teacher_forcing = False # teacher forcing/free decoding\n",
    "\n",
    "green_color = '#82B366'\n",
    "red_color = '#B85450'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "europarl_dir = Path(os.environ['EUROPARL_DATA_DIR'])\n",
    "ckpt_dir = Path(os.environ['EUROPARL_CKPT_DIR'])\n",
    "#iwslt14_dir = Path(os.environ['IWSLT14_DATA_DIR'])\n",
    "#ckpt_dir = Path(os.environ['IWSLT14_CKPT_DIR'])\n",
    "\n",
    "# Choose model\n",
    "model_type = 'baseline'\n",
    "seed = 5498 # 2253  2453  5498  9240\t9819\n",
    "\n",
    "hub = FairseqTransformerHub.from_pretrained(\n",
    "    ckpt_dir / f\"{model_type}/{seed}\",\n",
    "    checkpoint_file=f\"checkpoint_best.pt\",\n",
    "    data_name_or_path=(europarl_dir / \"processed_data/fairseq_preprocessed_data\").as_posix(), # processed data\n",
    "    #(data_name_or_path=iwslt14_dir / \"data-bin\").as_posix(), \n",
    ")\n",
    "NUM_LAYERS = 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get sample for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample from provided test data\n",
    "\n",
    "if data_sample == 'generate':\n",
    "    i = 386  # 0, 1 28, 45, 148 (pred_tok vs tgt_tok), 178, 16 (Hallucination), 421 (Hallucination)\n",
    "\n",
    "    src_sent, src_tok, src_tensor, tgt_sent, tgt_tok, tgt_tensor = hub.get_sample('test', i)\n",
    "    print(f\"\\nSource sentence: \\t {src_sent}\")\n",
    "    print(f\"Target sentence: \\t {tgt_sent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "das stimmt nicht !\n",
      "\n",
      "but this is not what happens .\n",
      "\n",
      "8\n",
      "das protokoll der gestrigen sitzung wurde verteilt .\n",
      "\n",
      "the minutes of yesterday 's sitting have been distributed .\n",
      "\n",
      "14\n",
      "sie versanden .\n",
      "\n",
      "they are silting up .\n",
      "\n",
      "33\n",
      "die kommission hat diesen appell vernommen .\n",
      "\n",
      "the commission heeded this call .\n",
      "\n",
      "43\n",
      "deshalb besteht die notwendigkeit einer europäischen richtlinie .\n",
      "\n",
      "therefore there is a need for a european directive .\n",
      "\n",
      "65\n",
      "gibt es einwände ?\n",
      "\n",
      "are there any other comments ?\n",
      "\n",
      "77\n",
      "zur empfehlung für die zweite lesung meier\n",
      "\n",
      "meier recommendation for second reading\n",
      "\n",
      "83\n",
      "natürlich gibt es da einen unterschied .\n",
      "\n",
      "of course there is a difference .\n",
      "\n",
      "86\n",
      "das ist der punkt !\n",
      "\n",
      "this is the whole point !\n",
      "\n",
      "87\n",
      "eine entsprechende änderung wird vorgenommen werden .\n",
      "\n",
      "the necessary correction will be made .\n",
      "\n",
      "105\n",
      "wir benötigen detaillierte , konkrete vorschläge .\n",
      "\n",
      "we need detailed , concrete proposals .\n",
      "\n",
      "121\n",
      "aber das hat leider tradition !\n",
      "\n",
      "but that unfortunately has become a tradition !\n",
      "\n",
      "130\n",
      "sicher nicht .\n",
      "\n",
      "surely not .\n",
      "\n",
      "134\n",
      "frau präsidentin , bleiben wir doch ernsthaft !\n",
      "\n",
      "madam president , surely we must take things seriously !\n",
      "\n",
      "158\n",
      "die kultur wird vernichtet .\n",
      "\n",
      "culture is being exterminated .\n",
      "\n",
      "163\n",
      "die industrie hatte dies erwartet .\n",
      "\n",
      "the industry was expecting that .\n",
      "\n",
      "174\n",
      "diese ansicht teilen wir überhaupt nicht .\n",
      "\n",
      "this is a view we do not in any way share .\n",
      "\n",
      "181\n",
      "die gemeinsame aussprache ist geschlossen .\n",
      "\n",
      "the joint debate is closed .\n",
      "\n",
      "198\n",
      "vielen dank , herr kommissar .\n",
      "\n",
      "thank you , commissioner .\n",
      "\n",
      "217\n",
      "genehmigung des protokolls\n",
      "\n",
      "approval of the minutes\n",
      "\n",
      "265\n",
      "tschad\n",
      "\n",
      "chad\n",
      "\n",
      "272\n",
      "wir haben für den bericht gestimmt .\n",
      "\n",
      "we are voting for the report .\n",
      "\n",
      "288\n",
      "wir sind heute enttäuscht .\n",
      "\n",
      "today , we are disappointed .\n",
      "\n",
      "308\n",
      "das sind sie nicht !\n",
      "\n",
      "not at all !\n",
      "\n",
      "322\n",
      "das ist rassismus !\n",
      "\n",
      "that is racism .\n",
      "\n",
      "335\n",
      "was müssen wir anschließend erleben ?\n",
      "\n",
      "and what do we have here ?\n",
      "\n",
      "337\n",
      "unsere bürger verlangen rechte .\n",
      "\n",
      "our citizens are demanding rights .\n",
      "\n",
      "346\n",
      "die hauptsorge ist die arbeitslosigkeit .\n",
      "\n",
      "the main concern is unemployment .\n",
      "\n",
      "364\n",
      "all dies fand ich sehr gut .\n",
      "\n",
      "i found it excellent .\n",
      "\n",
      "368\n",
      "china seinerseits ist gefordert .\n",
      "\n",
      "china , for its part , has expectations to live up to .\n",
      "\n",
      "386\n",
      "das ist natürlich falsch .\n",
      "\n",
      "that , of course , is untrue .\n",
      "\n",
      "399\n",
      "die kommission wird auch den änderungsantrag nr .\n",
      "\n",
      "the commission will also accept amendment no 7 .\n",
      "\n",
      "406\n",
      "wir kommen zur abstimmung .\n",
      "\n",
      "we shall now proceed to the vote .\n",
      "\n",
      "412\n",
      "wir alle sind davon betroffen .\n",
      "\n",
      "these things concern all of us .\n",
      "\n",
      "425\n",
      "das ist eine recht gute idee .\n",
      "\n",
      "this is quite a good idea .\n",
      "\n",
      "456\n",
      "wie konnte er sie nur übersehen ?\n",
      "\n",
      "but how could he have overlooked you ?\n",
      "\n",
      "457\n",
      "frau präsidentin , meine damen und herren !\n",
      "\n",
      "madam president , ladies and gentlemen .\n",
      "\n",
      "489\n",
      "ich habe eine ganz kurze frage .\n",
      "\n",
      "i have a very brief question .\n",
      "\n",
      "491\n",
      "europa ist krank .\n",
      "\n",
      "europe is sick .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_set_dir = europarl_dir / \"processed_data/\"\n",
    "src = \"de\"\n",
    "tgt = \"en\"\n",
    "tokenizer = \"bpe\"\n",
    "\n",
    "for i in range(508):\n",
    "    # index in dataset\n",
    "    src_word_sent, src_tok, src_tok_str, src_tensor, tgt_word_sent, tgt_tok, tgt_tok_str, tgt_tensor = hub.get_interactive_sample(i, test_set_dir, src, tgt, tokenizer, hallucination=True)\n",
    "    if src_tensor.size(0) <10:\n",
    "        print(i)\n",
    "        print(src_word_sent)\n",
    "        print(tgt_word_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "herr kommissar , liebe kolleginnen und kollegen ! zunächst herzlichen dank , herr burtone , für ihren bericht .\n",
      "\n",
      "commissioner , ladies and gentlemen , i should like to begin by thanking mr burtone for his report .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if data_sample == 'interactive':\n",
    "    # Get sample from Gold alignment dataset\n",
    "\n",
    "    # index in dataset\n",
    "    i = 3 # index in dataset\n",
    "    # 3, 100, 105, 107, 120 (example paper), 163 (error visible)\n",
    "    test_set_dir = europarl_dir / \"processed_data/\"\n",
    "    src = \"de\"\n",
    "    tgt = \"en\"\n",
    "    tokenizer = \"bpe\"\n",
    "    src_word_sent, src_tok, src_tok_str, src_tensor, tgt_word_sent, tgt_tok, tgt_tok_str, tgt_tensor = hub.get_interactive_sample(i, test_set_dir, src, tgt, tokenizer, hallucination=False)\n",
    "\n",
    "    print(src_word_sent)\n",
    "    print(tgt_word_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder output representations mixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_dir = europarl_dir / \"processed_data/\"\n",
    "src = \"de\"\n",
    "tgt = \"en\"\n",
    "tokenizer = \"bpe\"\n",
    "\n",
    "results_dict = defaultdict(list)\n",
    "\n",
    "for i in range(508):\n",
    "    # index in dataset\n",
    "    src_word_sent, src_tok, src_tok_str, src_tensor, tgt_word_sent, tgt_tok, tgt_tok_str, tgt_tensor = hub.get_interactive_sample(i, test_set_dir, src, tgt, tokenizer, hallucination=False)\n",
    "    if len(src_tok)>20 and len(src_tok)<23:\n",
    "        relevances_enc_self_attn = hub.get_contribution_rollout(src_tensor, tgt_tensor, 'l1', norm_mode='min_sum')['encoder.self_attn']\n",
    "        results_dict['means'].append(torch.diagonal(relevances_enc_self_attn[-1]).mean().detach().item())\n",
    "        results_dict['stds'].append(torch.diagonal(relevances_enc_self_attn[-1]).std().detach().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 39 sentences\n",
      "Mean:  0.3910024846211458\n",
      "Std:  0.19302802857680199\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_sentences = len(results_dict['means'])\n",
    "print(f'Total of {total_sentences} sentences')\n",
    "print('Mean: ', statistics.mean(results_dict['means']))\n",
    "print('Std: ', statistics.mean(results_dict['stds']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hallucinations Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(508):\n",
    "    # index in dataset\n",
    "    src_word_sent, src_tok, src_tok_str, src_tensor, tgt_word_sent, tgt_tok, tgt_tok_str, tgt_tensor = hub.get_interactive_sample(i, test_set_dir, src, tgt, tokenizer, hallucination=False)\n",
    "    prefix_tokens = torch.tensor([[3]]).to('cuda')\n",
    "    total_alti = hub.get_contribution_rollout(src_tensor, tgt_tensor, 'l1', norm_mode='min_sum')['total']\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "BEAM SEARCH\n",
      "\n",
      "-1.2187076807022095 \t <unk>ατhe committee on foreign affairs , human rights , common security and defence policy ( cdb ) .\n",
      "\n",
      "\n",
      "GREEDY DECODING with hypothesis 1\n",
      "\n",
      "Predicted sentence: \t mrατhe committee on foreign affairs , human rights , common security and defence policy ( cdb ) .\n"
     ]
    }
   ],
   "source": [
    "if not teacher_forcing:\n",
    "    tgt_tensor_free = []\n",
    "    # prefix_tokens = ['</s>','</s>','</s>']\n",
    "    # eos_id = hub.task.tgt_dict.eos_index # EOS token index\n",
    "    # prefix_tokens = torch.tensor([eos_id] + [hub.tgt_dict.index(t) for t in prefix_tokens])\n",
    "\n",
    "    prefix_tokens = torch.tensor([[3]]).to('cuda')\n",
    "    inference_step_args={'prefix_tokens': prefix_tokens}\n",
    "\n",
    "    print(\"\\n\\nBEAM SEARCH\\n\")\n",
    "    for pred in hub.generate(src_tensor, 1, inference_step_args = inference_step_args):\n",
    "        tgt_tensor_free.append(pred['tokens'])\n",
    "        pred_sent = hub.decode(pred['tokens'], hub.task.tgt_dict, as_string=True)\n",
    "        score = pred['score'].item()\n",
    "        print(f\"{score} \\t {pred_sent}\")\n",
    "\n",
    "    hypo = 0 # first hypothesis\n",
    "    tgt_tensor = tgt_tensor_free[hypo]\n",
    "    \n",
    "    # We add eos token at the beginning of sentence and delete it from the end\n",
    "    tgt_tensor = torch.cat([torch.tensor([hub.task.tgt_dict.eos_index]).to(tgt_tensor.device),\n",
    "                    tgt_tensor[:-1]\n",
    "                ]).to(tgt_tensor.device)\n",
    "    tgt_tok = hub.decode(tgt_tensor, hub.task.tgt_dict, as_string=False)\n",
    "    target_sentence = tgt_tok\n",
    "    source_sentence = src_tok\n",
    "\n",
    "    model_output, log_probs, encoder_out, layer_inputs, layer_outputs = hub.trace_forward(src_tensor, tgt_tensor)\n",
    "\n",
    "    print(f\"\\n\\nGREEDY DECODING with hypothesis {hypo+1}\\n\")\n",
    "    pred_log_probs, pred_tensor = torch.max(log_probs, dim=-1)\n",
    "    pred_tok = hub.decode(pred_tensor, hub.task.tgt_dict)\n",
    "    pred_sent = hub.decode(pred_tensor, hub.task.tgt_dict, as_string=True)\n",
    "    print(f\"Predicted sentence: \\t {pred_sent}\")\n",
    "    predicted_sentence = pred_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "#src_word_sent, src_tok, src_tok_str, src_tensor, tgt_word_sent, tgt_tok, tgt_tok_str, tgt_tensor = hub.get_interactive_sample(i, test_set_dir, src, tgt, tokenizer, hallucination=False)\n",
    "# prefix_tokens = torch.tensor([[3]]).to('cuda')\n",
    "# tgt_tensor = torch.cat([torch.tensor([hub.task.tgt_dict.eos_index, prefix_tokens]).to(tgt_tensor.device),\n",
    "#                 tgt_tensor[2:]\n",
    "#             ]).to(tgt_tensor.device)\n",
    "total_alti = hub.get_contribution_rollout(src_tensor, tgt_tensor, 'l1', norm_mode='min_sum')['total']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_translation(sample, prefix_tokens=None):\n",
    "    \"\"\"Get translation and total source contribution by ALTI\"\"\"\n",
    "    \n",
    "    inference_step_args={'prefix_tokens': prefix_tokens}\n",
    "    # Get sample from test set\n",
    "    sample = hub.get_interactive_sample(i, test_set_dir, src, tgt, tokenizer)\n",
    "    src_tensor = sample['src_tensor']\n",
    "    tgt_tensor_free = []\n",
    "    # Compute beam search (beam = 1 greedy decoding)\n",
    "    for pred in hub.generate(src_tensor, 1, inference_step_args = inference_step_args):\n",
    "        tgt_tensor_free.append(pred['tokens'])\n",
    "        pred_sent = hub.decode(pred['tokens'], hub.task.tgt_dict, as_string=True)\n",
    "        score = pred['score'].item()\n",
    "        #print(f\"{score} \\t {pred_sent}\")\n",
    "        \n",
    "\n",
    "    hypo = 0 # first hypothesis\n",
    "    tgt_tensor = tgt_tensor_free[hypo]\n",
    "    \n",
    "    # We add eos token at the beginning of sentence and delete it from the end\n",
    "    tgt_tensor = torch.cat([torch.tensor([hub.task.tgt_dict.eos_index]).to(tgt_tensor.device),\n",
    "                    tgt_tensor[:-1]\n",
    "                ]).to(tgt_tensor.device)\n",
    "\n",
    "    total_rollout = hub.get_contribution_rollout(src_tensor, tgt_tensor, 'l1', norm_mode='min_sum')['total'].detach()\n",
    "    # Get total source contribution\n",
    "    src_total_alti = total_rollout[-1][:,:src_tensor.size(0)].sum(dim=-1)\n",
    "    # We delete the first prediction (only source and bos contribution)\n",
    "    src_total_alti = src_total_alti[1:]\n",
    "\n",
    "    return pred_sent, src_total_alti\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_dir = europarl_dir / \"processed_data/\"\n",
    "src = \"de\"\n",
    "tgt = \"en\"\n",
    "tokenizer = \"bpe\"\n",
    "standard_translation = open('results/translations.txt', 'w', encoding=\"utf-8\")\n",
    "perturbed_translation = open('results/translations_unk.txt', 'w', encoding=\"utf-8\")\n",
    "src_alti_perturbed_list = []\n",
    "src_alti_list = []\n",
    "\n",
    "for i in range(508):\n",
    "    #inference_step_args = None\n",
    "    get_translation(sample, prefix_tokens=None)\n",
    "\n",
    "    \n",
    "    sample = hub.get_interactive_sample(i, test_set_dir, src, tgt, tokenizer)\n",
    "\n",
    "    # Standard translation\n",
    "    pred_sent, src_total_alti  = get_translation(sample, prefix_tokens=None)\n",
    "    standard_translation.write(pred_sent + '\\n')\n",
    "    src_alti_list.append(src_total_alti.tolist())\n",
    "\n",
    "    # Perturbed translation\n",
    "    prefix_tokens = torch.tensor([[3]]).to('cuda')\n",
    "    pred_sent_perturbed, src_alti_perturbed  = get_translation(sample, prefix_tokens=prefix_tokens)\n",
    "    perturbed_translation.write(pred_sent_perturbed + '\\n')\n",
    "    \n",
    "    src_alti_perturbed_list.append(src_alti_perturbed.tolist())\n",
    "\n",
    "standard_translation.close()\n",
    "perturbed_translation.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('results/src_alti.csv', 'w') as f:\n",
    "    write = csv.writer(f)\n",
    "    write.writerow(src_alti_list)\n",
    "\n",
    "with open('results/src_alti_unk.csv', 'w') as f:\n",
    "    write = csv.writer(f)\n",
    "    write.writerow(src_alti_perturbed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sacrebleu\n",
    "from sacrebleu.metrics import BLEU, CHRF, TER\n",
    "import nltk\n",
    "bleu = BLEU(max_ngram_order=4)\n",
    "def compute_bleu(reference, candidate):\n",
    "    return bleu.corpus_score([candidate],[[reference]]).score\n",
    "\n",
    "def read_file(path):\n",
    "    with open(path,'r') as f:\n",
    "        return list(f.readlines())\n",
    "#compute BLEU score against the reference for each baseline and model output\n",
    "refs = []\n",
    "model_translations = []\n",
    "hallucinations = []\n",
    "refs.append(read_file(\"data/de-en/test.en\"))\n",
    "model_translations.append(read_file(\"results/translations.txt\"))\n",
    "hallucinations.append(read_file(\"results/translations_unk.txt\"))\n",
    "diff_score = []\n",
    "scores = []\n",
    "\n",
    "for i in range(len(refs[0])):# len(refs[0])\n",
    "    model_score = sum([compute_bleu(refs[j][i],model_translations[j][i]) for j in range(len(model_translations))])/len(model_translations)\n",
    "    hallucinations_score = sum([compute_bleu(refs[j][i],hallucinations[j][i]) for j in range(len(hallucinations))])/len(hallucinations)\n",
    "    diff_score.append((i,model_score-hallucinations_score))\n",
    "    scores.append((i, model_score, hallucinations_score))\n",
    "    #print('Computed score', i, model_score, hallucinations_score)\n",
    "    #print('Computed score', i, model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply algorithm for extracting hallucination\n",
    "hallucination_set = []\n",
    "for (i, model_score, hallucinations_score) in scores:\n",
    "    if model_score > 0.2:\n",
    "        if hallucinations_score < 0.05:\n",
    "            hallucination_set.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 26,\n",
       " 65,\n",
       " 92,\n",
       " 95,\n",
       " 96,\n",
       " 103,\n",
       " 118,\n",
       " 131,\n",
       " 184,\n",
       " 196,\n",
       " 224,\n",
       " 239,\n",
       " 253,\n",
       " 269,\n",
       " 272,\n",
       " 282,\n",
       " 283,\n",
       " 320,\n",
       " 327,\n",
       " 335,\n",
       " 348,\n",
       " 355,\n",
       " 368,\n",
       " 371,\n",
       " 387,\n",
       " 408,\n",
       " 419,\n",
       " 451,\n",
       " 457,\n",
       " 466,\n",
       " 469]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucination_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, 'Unperturbed'), Text(0, 0, 'Perturbed')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_src_alti = []\n",
    "mean_preturbed_src_alti = []\n",
    "mean_alti = defaultdict(list)\n",
    "for i in hallucination_set:\n",
    "    mean_alti['Unperturbed'].append(statistics.mean(src_alti_list[i]))\n",
    "    mean_alti['Perturbed'].append(statistics.mean(src_alti_perturbed_list[i]))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(mean_alti.values(),whiskerprops=dict(linewidth=3.0))\n",
    "ax.set_xticklabels(mean_alti.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d90d8f5aa2056217711987bb6fa8dc20d62369a1e594ceedbb30cde0480a32e5"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
